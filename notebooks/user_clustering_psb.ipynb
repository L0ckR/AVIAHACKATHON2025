{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae178948",
   "metadata": {},
   "source": [
    "# Кластеризация пользователей по фичам (UMAP + KMeans)\n",
    "\n",
    "**Бизнес-цель.** Сжимаем поведение и сезонные сигналы пользователя в низкоразмерное представление и разбиваем на кластеры, чтобы:\n",
    "- понимать разные паттерны трат/сезонности и маппить их на продуктовые предложения;\n",
    "- увязывать кластеры с `socdem_cluster` и приоритизировать промо для близких групп;\n",
    "- находить «похожие» аудитории для апселла/кросс-сейла.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fafe36",
   "metadata": {},
   "source": [
    "## Описание фичей (что и зачем)\n",
    "- **daily_amount / high_spend_share** — интенсивность расходов; помогает выделить клиентов с высоким LTV и потребностью в кредитных линиях.\n",
    "- **saver_share / saver_share_30d** — стабильные «накопители», интересны депозиты, сберсчета, инвестиции.\n",
    "- **auto_day_share / home_day_share** — тематические паттерны (страхование авто/жилья, ремонт, овердрафт на ремонт).\n",
    "- **seasonal shares (pre_new_year, gifts_q1, back_to_school, summer, salary_window, social_benefits_window)** — сезонные пики, когда актуальны кредиты/кредитки/страховки/кэшбэк.\n",
    "- **unique_categories_mean / top_category** — разнообразие и основная категория, сигнал на кэшбэк или спец.программы.\n",
    "- **weekend_share** — кто тратит по выходным, релевантно travel/развлечения.\n",
    "- **Продуктовые таргеты (target_*)** — вероятностные признаки релевантности типов продуктов, используем как «полуметки» для подбора офферов внутри кластера.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48829418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути и параметры (оставляем как есть, только управляем через словари)\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "candidate_event_dirs = [\n",
    "    PROJECT_ROOT / 'data/marketplace/events',\n",
    "    PROJECT_ROOT / 'data/events',\n",
    "    PROJECT_ROOT / 'data copy/marketplace/events',\n",
    "]\n",
    "EVENTS_DIR = next((p for p in candidate_event_dirs if p.exists()), candidate_event_dirs[0])\n",
    "USERS_PATH = PROJECT_ROOT / 'data/users.pq'\n",
    "PRODUCTS_PATH = PROJECT_ROOT / 'psb_products_updated.json'\n",
    "\n",
    "FEATURE_PARAMS = {\n",
    "    'anchor_date': pd.Timestamp('2023-01-01'),\n",
    "    'n_files': 2,\n",
    "    'high_spend_quantile': 0.75,\n",
    "    'saver_window': 30,\n",
    "    'saver_min_periods': 10,\n",
    "    'saver_threshold': 0.8,\n",
    "    'salary_window_start_day': 25,\n",
    "    'salary_window_end_day': 5,\n",
    "    'social_benefits_start_day': 10,\n",
    "    'social_benefits_end_day': 20,\n",
    "    'pre_ny_start_day': 15,\n",
    "    'gifts_q1_end_day': 8,\n",
    "    'back_to_school_start': (8, 15),\n",
    "    'back_to_school_end': (9, 15),\n",
    "    'summer_months': [6, 7, 8],\n",
    "}\n",
    "\n",
    "CLUSTER_PARAMS = {\n",
    "    'n_clusters': 5,  # по умолчанию 5, можно поднять/понизить при интерпретации\n",
    "    'umap_n_neighbors': 25,\n",
    "    'umap_min_dist': 0.1,\n",
    "    'umap_random_state': 42,\n",
    "    'lof_neighbors': 25,  # для удаления шумовых точек\n",
    "    'lof_contamination': 0.02,  # доля выбросов (регулируйте при необходимости)\n",
    "}\n",
    "\n",
    "print('Используем каталог событий:', EVENTS_DIR)\n",
    "print('Каталог существует:', EVENTS_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_first_available(df: pd.DataFrame, candidates):\n",
    "    for col in candidates:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499211e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keyword_flag(df: pd.DataFrame, columns, keywords) -> pd.Series:\n",
    "    cols = [c for c in columns if c and c in df.columns]\n",
    "    if not cols:\n",
    "        return pd.Series(False, index=df.index)\n",
    "    text = df[cols[0]].fillna('').astype(str)\n",
    "    for col in cols[1:]:\n",
    "        text = text.str.cat(' ' + df[col].fillna('').astype(str))\n",
    "    text = text.str.lower()\n",
    "    mask = pd.Series(False, index=df.index)\n",
    "    for kw in keywords:\n",
    "        mask = mask | text.str.contains(kw)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abba904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_calendar_flags(dates: pd.Series, cfg: dict) -> pd.DataFrame:\n",
    "    d = pd.to_datetime(dates)\n",
    "    day = d.dt.day\n",
    "    month = d.dt.month\n",
    "    flags = pd.DataFrame(index=dates.index)\n",
    "    flags['is_pre_new_year'] = (month == 12) & (day >= cfg['pre_ny_start_day'])\n",
    "    flags['is_gifts_q1'] = (month == 2) | ((month == 3) & (day <= cfg['gifts_q1_end_day']))\n",
    "    start_m, start_d = cfg['back_to_school_start']\n",
    "    end_m, end_d = cfg['back_to_school_end']\n",
    "    flags['is_back_to_school'] = ((month == start_m) & (day >= start_d)) | ((month == end_m) & (day <= end_d))\n",
    "    flags['is_summer'] = month.isin(cfg['summer_months'])\n",
    "    flags['is_salary_window'] = (day >= cfg['salary_window_start_day']) | (day <= cfg['salary_window_end_day'])\n",
    "    flags['is_social_benefits_window'] = (day >= cfg['social_benefits_start_day']) & (day <= cfg['social_benefits_end_day'])\n",
    "    return flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b91515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_event_time(df: pd.DataFrame, anchor_date: pd.Timestamp) -> pd.DataFrame:\n",
    "    # timedelta -> anchor_date + delta; datetime -> как есть\n",
    "    df = df.copy()\n",
    "    if df.empty:\n",
    "        df['event_dt'] = pd.NaT\n",
    "        df['date'] = pd.NaT\n",
    "        return df\n",
    "    time_col = choose_first_available(df, ['event_time', 'timestamp', 'time', 'ts'])\n",
    "    if time_col is None:\n",
    "        raise ValueError('Не нашли колонку со временем события')\n",
    "    raw = df[time_col]\n",
    "    if np.issubdtype(raw.dtype, np.timedelta64):\n",
    "        event_dt = anchor_date + pd.to_timedelta(raw)\n",
    "    else:\n",
    "        event_dt = pd.to_datetime(raw, errors='coerce', utc=True)\n",
    "        try:\n",
    "            event_dt = event_dt.dt.tz_convert(None)\n",
    "        except TypeError:\n",
    "            pass\n",
    "    df['event_dt'] = event_dt\n",
    "    df['date'] = df['event_dt'].dt.floor('D')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd608738",
   "metadata": {},
   "source": [
    "## Загрузка и предобработка событий\n",
    "- Фильтр `action_type != view` — оставляем действия, убираем шум просмотров.\n",
    "- Нормализация времени (timedelta -> anchor_date).\n",
    "- Сумма/категория, тематические флаги.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adce940",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVENTS_DIR.exists():\n",
    "    event_files = sorted(EVENTS_DIR.glob('*.pq'))\n",
    "else:\n",
    "    event_files = []\n",
    "print(f'Файлов с событиями: {len(event_files)}')\n",
    "print('Примеры файлов:', [f.name for f in event_files[:3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efdf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "if event_files:\n",
    "    n_files = FEATURE_PARAMS['n_files']\n",
    "    use_files = event_files if n_files is None else event_files[:n_files]\n",
    "    raw_frames = [pd.read_parquet(f) for f in use_files]\n",
    "    raw_events = pd.concat(raw_frames, ignore_index=True)\n",
    "else:\n",
    "    use_files = []\n",
    "    raw_events = pd.DataFrame()\n",
    "print(f'Загружено {len(raw_events):,} строк из {len(use_files)} файлов')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_before = len(raw_events)\n",
    "if 'action_type' in raw_events.columns:\n",
    "    events_filtered = raw_events[raw_events['action_type'].fillna('') != 'view'].copy()\n",
    "else:\n",
    "    events_filtered = raw_events.copy()\n",
    "rows_after = len(events_filtered)\n",
    "print(f'Строк до: {rows_before:,} / после удаления view: {rows_after:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = standardize_event_time(events_filtered, FEATURE_PARAMS['anchor_date'])\n",
    "if events.empty:\n",
    "    print('Нет событий после фильтрации')\n",
    "else:\n",
    "    events = events.dropna(subset=['event_dt'])\n",
    "    events['user_id'] = pd.to_numeric(events['user_id'], errors='coerce').astype('Int64')\n",
    "    events = events.dropna(subset=['user_id'])\n",
    "    events['user_id'] = events['user_id'].astype(int)\n",
    "print('Событий после нормализации:', events.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b028fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_col = choose_first_available(events, ['price', 'amount', 'sum', 'value'])\n",
    "if amount_col:\n",
    "    events['amount'] = pd.to_numeric(events[amount_col], errors='coerce').fillna(0.0)\n",
    "else:\n",
    "    events['amount'] = 0.0\n",
    "category_col = choose_first_available(events, ['category', 'category_id', 'subdomain', 'domain', 'brand_id'])\n",
    "if category_col:\n",
    "    events[category_col] = events[category_col].astype(str)\n",
    "print('Колонка суммы:', amount_col)\n",
    "print('Колонка категории:', category_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde80eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_candidates = [category_col, 'brand_id', 'domain', 'subdomain', 'item_id', 'action_type']\n",
    "auto_keywords = ['auto', 'car', 'fuel', 'gas', 'azs', 'sto', 'parking', 'tire', 'taxi']\n",
    "home_keywords = ['home', 'repair', 'remont', 'stroi', 'furniture', 'kitchen', 'flat', 'rent', 'mortgage', 'paint']\n",
    "\n",
    "events['auto_related'] = detect_keyword_flag(events, category_candidates, auto_keywords)\n",
    "events['home_related'] = detect_keyword_flag(events, category_candidates, home_keywords)\n",
    "print('auto_related mean:', events['auto_related'].mean() if len(events) else 0)\n",
    "print('home_related mean:', events['home_related'].mean() if len(events) else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44845e8",
   "metadata": {},
   "source": [
    "## Дневные фичи и сезонные окна\n",
    "- Сумма/частота за день, разнообразие категорий\n",
    "- Самая значимая категория дня\n",
    "- Авто/ремонт активность в день\n",
    "- High-spend дни и «накопители»\n",
    "- Сезонность (предНГ, подарки, школа, лето, зарплаты, соцвыплаты)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdbf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'daily_amount': ('amount', 'sum'),\n",
    "    'daily_events': ('event_dt', 'size'),\n",
    "}\n",
    "if category_col:\n",
    "    agg_dict['unique_categories'] = (category_col, 'nunique')\n",
    "\n",
    "daily = events.groupby(['user_id', 'date']).agg(**agg_dict).reset_index() if len(events) else pd.DataFrame()\n",
    "if len(daily):\n",
    "    daily = daily.sort_values(['user_id', 'date'])\n",
    "print('daily shape:', daily.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(daily) and category_col:\n",
    "    cat_daily = (\n",
    "        events\n",
    "        .groupby(['user_id', 'date', category_col])\n",
    "        .agg(category_amount=('amount', 'sum'), category_events=('amount', 'size'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    top_cat = (\n",
    "        cat_daily\n",
    "        .sort_values(['category_amount', 'category_events'], ascending=False)\n",
    "        .groupby(['user_id', 'date'])\n",
    "        .head(1)\n",
    "        .rename(columns={category_col: 'top_category'})\n",
    "    )\n",
    "    daily = daily.merge(top_cat[['user_id', 'date', 'top_category', 'category_amount', 'category_events']], on=['user_id', 'date'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8c1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_col, target_col in [('auto_related', 'is_auto_active'), ('home_related', 'is_home_repair_period')]:\n",
    "    if source_col in events.columns and len(events):\n",
    "        flag = events.groupby(['user_id', 'date'])[source_col].any().reset_index().rename(columns={source_col: target_col})\n",
    "        daily = daily.merge(flag, on=['user_id', 'date'], how='left') if len(daily) else flag\n",
    "    else:\n",
    "        daily[target_col] = False\n",
    "for col in ['is_auto_active', 'is_home_repair_period']:\n",
    "    if col in daily.columns:\n",
    "        daily[col] = daily[col].fillna(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(daily):\n",
    "    q = FEATURE_PARAMS['high_spend_quantile']\n",
    "    p_user = daily.groupby('user_id')['daily_amount'].transform(lambda s: s.quantile(q))\n",
    "    daily['is_high_spend_day'] = daily['daily_amount'] >= p_user\n",
    "\n",
    "    low_spend_flag = daily['daily_amount'] <= daily.groupby('user_id')['daily_amount'].transform('median')\n",
    "    win = FEATURE_PARAMS['saver_window']\n",
    "    min_p = FEATURE_PARAMS['saver_min_periods']\n",
    "    daily['saver_share_30d'] = low_spend_flag.groupby(daily['user_id']).transform(lambda s: s.rolling(win, min_periods=min_p).mean())\n",
    "    daily['is_saver'] = daily['saver_share_30d'] >= FEATURE_PARAMS['saver_threshold']\n",
    "else:\n",
    "    daily['is_high_spend_day'] = []\n",
    "    daily['saver_share_30d'] = []\n",
    "    daily['is_saver'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a995177",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(daily):\n",
    "    calendar_flags = build_calendar_flags(daily['date'], FEATURE_PARAMS)\n",
    "    daily = pd.concat([daily, calendar_flags], axis=1)\n",
    "    daily['month'] = pd.to_datetime(daily['date']).dt.month\n",
    "    daily['dayofweek'] = pd.to_datetime(daily['date']).dt.dayofweek\n",
    "    daily['is_weekend'] = daily['dayofweek'] >= 5\n",
    "    daily['weekofyear'] = pd.to_datetime(daily['date']).dt.isocalendar().week.astype(int)\n",
    "else:\n",
    "    daily['month'] = []\n",
    "    daily['dayofweek'] = []\n",
    "    daily['is_weekend'] = []\n",
    "    daily['weekofyear'] = []\n",
    "print(daily.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111bbb5",
   "metadata": {},
   "source": [
    "## Пользовательские фичи (агрегация по user_id)\n",
    "Копим поведение в стационарные метрики для кластеризации и UMAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d2042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(daily):\n",
    "    user_feats = daily.groupby('user_id').agg(\n",
    "        days=('date', 'nunique'),\n",
    "        total_amount=('daily_amount', 'sum'),\n",
    "        mean_amount=('daily_amount', 'mean'),\n",
    "        median_amount=('daily_amount', 'median'),\n",
    "        max_amount=('daily_amount', 'max'),\n",
    "        mean_events=('daily_events', 'mean'),\n",
    "        unique_categories_mean=('unique_categories', 'mean'),\n",
    "        auto_day_share=('is_auto_active', 'mean'),\n",
    "        home_day_share=('is_home_repair_period', 'mean'),\n",
    "        high_spend_share=('is_high_spend_day', 'mean'),\n",
    "        saver_share=('is_saver', 'mean'),\n",
    "        weekend_share=('is_weekend', 'mean'),\n",
    "        pre_ny_share=('is_pre_new_year', 'mean'),\n",
    "        gifts_q1_share=('is_gifts_q1', 'mean'),\n",
    "        bts_share=('is_back_to_school', 'mean'),\n",
    "        summer_share=('is_summer', 'mean'),\n",
    "        salary_window_share=('is_salary_window', 'mean'),\n",
    "        social_benefits_share=('is_social_benefits_window', 'mean'),\n",
    "    ).reset_index()\n",
    "else:\n",
    "    user_feats = pd.DataFrame(columns=['user_id'])\n",
    "print('user_feats shape:', user_feats.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a3bda",
   "metadata": {},
   "source": [
    "## Продуктовые таргеты + демография\n",
    "Используем сигнальные фичи как мягкие таргеты типов продуктов, склеиваем с socdem_cluster/region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ba47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_product_mapping(df: pd.DataFrame, feature_to_types: dict, product_types: list) -> pd.DataFrame:\n",
    "    targets = pd.DataFrame(index=df.index)\n",
    "    for pt in product_types:\n",
    "        targets[f'target_{pt}'] = False\n",
    "    for feat, pts in feature_to_types.items():\n",
    "        if feat not in df.columns:\n",
    "            continue\n",
    "        for pt in pts:\n",
    "            if pt in product_types:\n",
    "                targets[f'target_{pt}'] = targets[f'target_{pt}'] | df[feat].fillna(False)\n",
    "    target_cols = [f'target_{pt}' for pt in product_types]\n",
    "    targets['candidate_product_types'] = targets[target_cols].apply(lambda r: [pt for pt, flag in zip(product_types, r) if flag], axis=1)\n",
    "    return targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PRODUCTS_PATH, 'r') as f:\n",
    "    products = json.load(f)\n",
    "product_types = sorted({p['product_type'] for p in products})\n",
    "feature_to_types = {\n",
    "    'is_pre_new_year': ['loan', 'credit_card'],\n",
    "    'is_gifts_q1': ['credit_card', 'debit_card', 'premium_service'],\n",
    "    'is_back_to_school': ['credit_card', 'loan', 'savings_account', 'deposit'],\n",
    "    'is_summer': ['insurance', 'debit_card'],\n",
    "    'is_salary_window': ['debit_card', 'deposit'],\n",
    "    'is_social_benefits_window': ['savings_account', 'deposit'],\n",
    "    'is_high_spend_day': ['loan', 'credit_card'],\n",
    "    'is_saver': ['deposit', 'savings_account', 'investment'],\n",
    "    'is_auto_active': ['insurance', 'debit_card'],\n",
    "    'is_home_repair_period': ['mortgage', 'loan', 'insurance'],\n",
    "}\n",
    "\n",
    "if len(daily):\n",
    "    targets_daily = apply_feature_product_mapping(daily, feature_to_types, product_types)\n",
    "    daily_with_targets = pd.concat([daily, targets_daily], axis=1)\n",
    "    user_targets = daily_with_targets.groupby('user_id')[targets_daily.columns].mean().reset_index()\n",
    "else:\n",
    "    user_targets = pd.DataFrame(columns=['user_id'])\n",
    "print('user_targets shape:', user_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598195f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_parquet(USERS_PATH) if USERS_PATH.exists() else pd.DataFrame(columns=['user_id'])\n",
    "if not users_df.empty:\n",
    "    users_df['socdem_cluster'] = users_df['socdem_cluster'].astype('Int64')\n",
    "\n",
    "full = user_feats.merge(user_targets, on='user_id', how='left') if len(user_feats) else pd.DataFrame()\n",
    "if not users_df.empty:\n",
    "    full = full.merge(users_df, on='user_id', how='left')\n",
    "print('full shape:', full.shape)\n",
    "print(full.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db84541",
   "metadata": {},
   "source": [
    "## Матрица для кластеризации\n",
    "- только числовые фичи\n",
    "- fillna=0, StandardScaler\n",
    "- PCA (check дисперсия)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8d432",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in full.columns if c not in ['user_id', 'candidate_product_types'] and pd.api.types.is_numeric_dtype(full[c])]\n",
    "X = full[feature_cols].copy()\n",
    "X = X.fillna(0)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) if len(full) else np.empty((0, len(feature_cols)))\n",
    "\n",
    "pca = PCA(n_components=min(10, len(feature_cols))) if len(feature_cols) else None\n",
    "pca_res = pca.fit_transform(X_scaled) if pca else np.empty((0, 0))\n",
    "if pca:\n",
    "    explained = pca.explained_variance_ratio_.cumsum()\n",
    "    print('PCA cumulative variance:', explained)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6fd3a0",
   "metadata": {},
   "source": [
    "## Удаление шумов (LOF на исходных фичах)\n",
    "- Local Outlier Factor выкидывает низкоплотные точки\n",
    "- регулируйте `lof_contamination` и `lof_neighbors` при необходимости\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac206aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(full):\n",
    "    lof = LocalOutlierFactor(n_neighbors=CLUSTER_PARAMS['lof_neighbors'], contamination=CLUSTER_PARAMS['lof_contamination'])\n",
    "    lof_labels = lof.fit_predict(X_scaled)\n",
    "    mask_inliers = lof_labels == 1\n",
    "    print(f'Inliers: {mask_inliers.sum()} / {len(mask_inliers)}')\n",
    "    full = full.loc[mask_inliers].reset_index(drop=True)\n",
    "    X_scaled = X_scaled[mask_inliers]\n",
    "else:\n",
    "    print('Нет данных для LOF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf6ce9b",
   "metadata": {},
   "source": [
    "## UMAP + KMeans\n",
    "- UMAP: снижает размерность для визуальной интерпретации\n",
    "- KMeans: выделяет группы для продуктовых стратегий\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b72927",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(full):\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=CLUSTER_PARAMS['umap_n_neighbors'],\n",
    "        min_dist=CLUSTER_PARAMS['umap_min_dist'],\n",
    "        random_state=CLUSTER_PARAMS['umap_random_state'],\n",
    "        n_components=2,\n",
    "    )\n",
    "    embedding = reducer.fit_transform(X_scaled)\n",
    "    kmeans = KMeans(n_clusters=CLUSTER_PARAMS['n_clusters'], n_init='auto', random_state=42)\n",
    "    clusters = kmeans.fit_predict(embedding)\n",
    "\n",
    "    full['cluster'] = clusters\n",
    "    full['umap_x'] = embedding[:, 0]\n",
    "    full['umap_y'] = embedding[:, 1]\n",
    "    print(full[['user_id', 'cluster', 'umap_x', 'umap_y']].head())\n",
    "else:\n",
    "    full['cluster'] = []\n",
    "    full['umap_x'] = []\n",
    "    full['umap_y'] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e04de",
   "metadata": {},
   "source": [
    "## Визуализация UMAP\n",
    "- Цвет — кластер\n",
    "- Можно перекрасить по `socdem_cluster` для проверки соответствия демографии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f857393",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(full):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=full, x='umap_x', y='umap_y', hue='cluster', palette='tab10', s=10, linewidth=0)\n",
    "    plt.title('UMAP проекция пользователей (по фичам)')\n",
    "    plt.legend(title='cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd7dc1",
   "metadata": {},
   "source": [
    "## Профили кластеров\n",
    "Смотрим размер, средние фичи, соотношение socdem_cluster и продуктовых таргетов — чтобы понять, кому и что предлагать.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c846b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(full):\n",
    "    cluster_sizes = full['cluster'].value_counts().sort_index().rename('count')\n",
    "    print('Размеры кластеров:', cluster_sizes)\n",
    "\n",
    "    feature_summary = full.groupby('cluster')[feature_cols].mean()\n",
    "    print('Средние фичи по кластерам (первые 5 колонок):')\n",
    "    print(feature_summary.iloc[:, :5])\n",
    "\n",
    "    if 'socdem_cluster' in full.columns:\n",
    "        socdem_summary = full.groupby('cluster')['socdem_cluster'].value_counts(normalize=True).rename('share')\n",
    "        print('Распределение socdem_cluster внутри кластеров (share):')\n",
    "        print(socdem_summary.head(20))\n",
    "\n",
    "    target_cols = [c for c in full.columns if c.startswith('target_')]\n",
    "    if target_cols:\n",
    "        target_summary = full.groupby('cluster')[target_cols].mean()\n",
    "        print('Средние продуктовые таргеты по кластерам:')\n",
    "        print(target_summary)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
